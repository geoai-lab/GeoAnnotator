{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc90c3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\VS_Code_projects\\\\geo-app\\\\api\\\\NeuroTPR'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcc06778",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained NeuroTPR model\n",
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"location_name\": \"Buffalo\", \"start_idx\": 1, \"end_idx\": 7}, {\"location_name\": \"New York State\", \"start_idx\": 22, \"end_idx\": 35}] ==> example of the result\n"
     ]
    }
   ],
   "source": [
    "from neurotpr import geoparse\n",
    "import pandas as pd \n",
    " # \"sqlite:///HarveyTwitter.db\"\n",
    "os.chdir('../')\n",
    "geoparse.load_model(\"NeuroTPR/\")\n",
    "result = geoparse.topo_recog(\"Buffalo is a city in New York State.\")\n",
    "print(\"{} ==> example of the result\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c81044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e6e3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurotpr.geoparse import addCharInformatioin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47b41e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['RT', 1, 'NN'],\n",
       " [':', 4, ':'],\n",
       " ['Water', 6, 'NNP'],\n",
       " ['is', 12, 'VBZ'],\n",
       " ['seeping', 15, 'VBG'],\n",
       " ['into', 23, 'IN'],\n",
       " ['the', 28, 'DT'],\n",
       " ['studio', 32, 'NN'],\n",
       " ['from', 39, 'IN'],\n",
       " ['Buffalo', 44, 'NNP'],\n",
       " ['Bayou', 52, 'NNP'],\n",
       " ['.', 58, '.'],\n",
       " ['About', 60, 'IN'],\n",
       " ['to', 66, 'TO'],\n",
       " ['move', 69, 'VB'],\n",
       " ['broadcast', 74, 'NN'],\n",
       " ['to', 84, 'TO'],\n",
       " ['second', 87, 'JJ'],\n",
       " ['floor', 94, 'NN'],\n",
       " ['.', 100, '.'],\n",
       " ['Harvey', 102, 'NNP'],\n",
       " ['KHOU11', 109, 'NNP'],\n",
       " ['URL', 116, 'NNP']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoparse.preprocess_tweet(df['text'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50dd66d",
   "metadata": {},
   "source": [
    "# We now connect to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2eb6c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to access the database \n",
    "from sqlite3 import connect\n",
    "conn = connect(\"postgres://../HarveyTwitter.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7fcafc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT text, id, created_at, neuro_data FROM `NeuroTPR-dataset`', conn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d34d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_the_preprocess(text):\n",
    "    text = delete_emoji(text)\n",
    "    tweet_token = TweetTokenizer(preserve_case=True, strip_handles=True, reduce_len=True)\n",
    "    results = tweet_token.tokenize(text)\n",
    "    results = [item[1:] if (item.startswith(\"#\") and len(item)>1) else item for item in results]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "efc0f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indexes(before_word, word, after_word, original_text):\n",
    "    \n",
    "    if len(before_word) == 0 and len(after_word) > 0:\n",
    "        pattern = r'(?<=).*({}).*(?={})'.format(word,after_word)\n",
    "    elif len(after_word) == 0 and len(before_word) > 0:\n",
    "        pattern = r'(?<={}).*({}).*(?=)'.format(before_word,word)\n",
    "    elif len(after_word) == 0 and len(before_word) == 0:\n",
    "        pattern = r'(?<=).*({}).*(?=)'.format(word)\n",
    "    else : # both greater than one \n",
    "        pattern = r'(?<={}).*({}).*(?={})'.format(before_word,word,after_word)\n",
    "    print(pattern),print(word)\n",
    "    substring = re.search(pattern,original_text,flags=re.MULTILINE)\n",
    "    if substring == None:\n",
    "        print(row)\n",
    "    actual_index = substring.span(1)\n",
    "   \n",
    "    return actual_index[0],actual_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427fab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "function escapeRegExp(text) {\n",
    "  return text.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&');\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "7cfc1aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fkldfm\\\\&kldmfkld!kdfldkfm\\\\?fkdlmfd\\\\('"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_string = \"fkldfm&kldmfkld!kdfldkfm?fkdlmfd(\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "6e03570c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fkldfm&kldmfkld!kdfldkfm\\\\?fkdlmfd('"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_string.replace('?', \"\\\\\" + \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "05e8babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "new_jsons = []\n",
    "def fix_special_characters(text):\n",
    "    new_string = text\n",
    "    list_to_replace = \"^&.|?*+()[]{}â€¦,\"\n",
    "    for char in list_to_replace:\n",
    "        new_string = new_string.replace(char, '')\n",
    "    return new_string\n",
    "def find_indexes(before_word, word, after_word, original_text):\n",
    "    after_word = fix_special_characters(after_word)\n",
    "    before_word = fix_special_characters(before_word)\n",
    "    if len(before_word) == 0 and len(after_word) > 0:\n",
    "        pattern = r'(?<=).*({}).*(?={})'.format(word,after_word)\n",
    "    elif len(after_word) == 0 and len(before_word) > 0:\n",
    "        pattern = r'(?<={}).*({}).*(?=)'.format(before_word,word)\n",
    "    elif len(after_word) == 0 and len(before_word) == 0:\n",
    "        pattern = r'(?<=).*({}).*(?=)'.format(word)\n",
    "    else : # both greater than one \n",
    "        pattern = r'(?<={}).*({}).*(?={})'.format(before_word,word,after_word)\n",
    "    substring = re.search(pattern,original_text,flags=re.MULTILINE)\n",
    "    if substring == None:\n",
    "        print(row)\n",
    "    actual_index = substring.span(1)\n",
    "    return actual_index[0],actual_index[1]\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    jsoned = json.loads(row['neuro_data'])\n",
    "    original_text = row['text'].replace('\\n',' ')\n",
    "    text_part = \" \".join(return_the_preprocess(row['text']))\n",
    "  \n",
    "    for predicted in jsoned:\n",
    "        var_right_idx = row['text'].find(predicted['location_name'])\n",
    "        \n",
    "        before = text_part[:predicted['start_idx']-1]\n",
    "        after = text_part[predicted['end_idx']:]\n",
    "        before = fix_special_characters(before)\n",
    "        after = fix_special_characters(after)\n",
    "        before_word = re.sub(' +', ' ',before).strip().split(' ')[-1]\n",
    "        after_word = re.sub(' +', ' ',after).strip().split(' ')[0]\n",
    "        before_word = re.sub(r'http\\S+', '', before_word ).replace('/','')\n",
    "        after_word = re.sub(r'http\\S+', '', after_word ).replace('/','')\n",
    "        words = predicted['location_name'].split(\" \")\n",
    "        start = find_indexes(before_word,words[0], after_word, original_text)\n",
    "        end =  find_indexes(before_word, words[-1], after_word, original_text)[1] if len(words)>1 else start[1]\n",
    "        predicted['start_idx'] = start[0]\n",
    "        predicted['end_idx'] = end\n",
    "    new_jsons.append(jsoned)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "3b7d9352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json.dumps(json.loads(df.iloc[1]['neuro_data'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "ba56a192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT  Looking ugly  View from the 14th floor of the '"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "dda6fb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 915 AM Galveston Harvey Fox26 https//tco/rYkc1gbIrQ'"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "586dd7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'915'"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "d71e4e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @ifrankyy: League City right now #harvey #LeagueCity'"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text[:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "2e16822a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "0d89a543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LeagueCity'"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['text'][45:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "db5eb95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dallas shelters'"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['text'][27:42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "8f2f64d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'location_name': 'League City', 'start_idx': 45, 'end_idx': 55}]"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['correction_of_neuro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "b9200f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'location_name': 'Dallas shelters', 'start_idx': 27, 'end_idx': 42}]]"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "f470ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correction_of_neuro'] = new_jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "87072311",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df[1:].iterrows():\n",
    "    for loc in row['correction_of_neuro']:\n",
    "        correction_word = row['text'][loc['start_idx']:loc['end_idx']]\n",
    "        if correction_word == 'M.O. ':\n",
    "            continue \n",
    "        if (loc['location_name'] != correction_word.replace('#','').replace('\\n',' ')):\n",
    "            raise ValueError('A very specific bad thing happened.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "6ec10f02",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-642-5918bf9b1478>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'correction_of_neuro'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"location_name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "df.iloc[1]['correction_of_neuro'][\"location_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "b8348db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @rfelliott: The @RedCross has opened a Greenspoint-area shelter at the M.O. Campbell Center. No one here yet. #Harvey https://t.co/Zl4Loâ€¦'"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "94bde6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Campbell Center'"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['text'][79:94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "107e9f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'location_name': 'M . O .', 'start_idx': 74, 'end_idx': 79},\n",
       " {'location_name': 'Campbell Center', 'start_idx': 79, 'end_idx': 94}]"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['correction_of_neuro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "0262fa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"location_name\": \"Texas Texas\", \"start_idx\": 1, \"end_idx\": 11}, {\"location_name\": \"Texas\", \"start_idx\": 18, \"end_idx\": 22}, {\"location_name\": \"Rockport Texas\", \"start_idx\": 55, \"end_idx\": 68}]'"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoparse.topo_recog('Texas Texas RT @TuiteroSismico: Texas Varios edificios colapsados en #Rockport #Texas debido al #HuracÃ¡n #Harvey #HurricaneHarvey https://t.co/Vn3BnepEaZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "085d150c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"location_name\": \"League City\", \"start_idx\": 6, \"end_idx\": 16}]'"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['neuro_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "1e18df74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'location_name': 'League City', 'start_idx': 45, 'end_idx': 55}]"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['correction_of_neuro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "db8a168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @TuiteroSismico: Varios edificios colapsados en #Rockport #Texas debido al #HuracÃ¡n #Harvey #HurricaneHarvey https://t.co/Vn3BnepEaZ\n"
     ]
    }
   ],
   "source": [
    "print(row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "5d7672a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LeagueCity'"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['text'][45:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "d70076c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"location_name\": \"League City\", \"start_idx\": 6, \"end_idx\": 16}]'"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['neuro_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "a634c0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @ifrankyy: League City right now #harvey #LeagueCity https://t.co/npuWSzza4A'"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "f5d57da0",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "unterminated character set at position 27",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-388-2db8dae72754>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfind_indexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbefore_word\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-387-0527ff50bce6>\u001b[0m in \u001b[0;36mfind_indexes\u001b[1;34m(before_word, word, after_word, original_text)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfind_indexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbefore_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'(?<=[{}]).*({}).*(?=[{}])'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbefore_word\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mafter_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0msubstring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moriginal_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMULTILINE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msubstring\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NeuroTPR\\lib\\re.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[0;32m    181\u001b[0m     a match object, or None if no match was found.\"\"\"\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NeuroTPR\\lib\\re.py\u001b[0m in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NeuroTPR\\lib\\sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NeuroTPR\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(str, flags, pattern)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NeuroTPR\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[1;32m--> 416\u001b[1;33m                            not nested and not items))\n\u001b[0m\u001b[0;32m    417\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NeuroTPR\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    694\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mlookbehindgroups\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m                             \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookbehindgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m                     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnested\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mdir\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mlookbehindgroups\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NeuroTPR\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[1;32m--> 416\u001b[1;33m                            not nested and not items))\n\u001b[0m\u001b[0;32m    417\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NeuroTPR\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    521\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mthis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m                     raise source.error(\"unterminated character set\",\n\u001b[1;32m--> 523\u001b[1;33m                                        source.tell() - here)\n\u001b[0m\u001b[0;32m    524\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mthis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"]\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mset\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: unterminated character set at position 27"
     ]
    }
   ],
   "source": [
    " find_indexes(before_word,words[0], after_word, original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "f0a7f1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\sCaldwell\\\\sCo'"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "1951e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correction_of_neuro'] = df['correction_of_neuro'].apply(lambda x: json.dumps(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "80353e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @NWSSanAntonio: ***TS #Harvey Update***\n",
      "\n",
      "1. Major flooding ongoing in Bastrop/Caldwell Co.\n",
      "2. Harvey barely moving.\n",
      "\n",
      "Full details -&gt; httâ€¦\n"
     ]
    }
   ],
   "source": [
    "print(original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "24a2bf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location_name': 'Caldwell Co', 'start_idx': 75, 'end_idx': 85}"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a4e6039a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TX'"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text[88:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "50e953d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"location_name\": \"Buffalo Bayou\", \"start_idx\": 44, \"end_idx\": 56}]'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['neuro_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c047bec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'location_name': 'Buffalo Bayou', 'start_idx': 55, 'end_idx': 56}]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsoned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e3158a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted['start_idx'] = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e2b48656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location_name': 'Buffalo Bayou', 'start_idx': 55, 'end_idx': 56}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fa62ce39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buffalo Bayou'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "05830644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "(?<=Houston).*(RT @ReadyHarris: OPEN SHELTER: North Shore 9th Grade Center -  13501 Hollypark Houston, TX 77015 #Harvey @DisasterPIO).*(?=77015)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'nter -  13501'"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = row['text']\n",
    "pattern = \"(?<={}).*({}).*(?={})\".format(before_word,s,after_word)\n",
    "substring = re.search(pattern,s,flags=re.MULTILINE)\n",
    "print(substring)\n",
    "print(pattern)\n",
    "s[55:68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b034fd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?<=from).*(Buffalo\\\\sBayou).*(?=About)'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ec13d48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 68)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substring.span(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "529df8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?<=from).*(Buffalo\\\\Bayou).*(?=About)'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3071f3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'About'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4df49e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re.search(r'banana',\"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "618a813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = geoparse.topo_recog(df['text'].iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5296bd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @ReadyHarris: OPEN SHELTER: North Shore 9th Grade Center -  13501 Hollypark Houston, TX 77015 #Harvey @DisasterPIO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' SHELTER: '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['text'].iloc[2])\n",
    "df['text'].iloc[2][21:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99fc24d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurotpr.geoparse import delete_emoji\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "def preprocess_right_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "238fd305",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['text'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ntlk.tokenize.treebank import TreebankWordDek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c96e3794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<nltk.tokenize.casual.TweetTokenizer object at 0x00000219E84C3CC0>\n",
      "North Shore\n",
      "['RT', ':', 'OPEN', 'SHELTER', ':', 'North', 'Shore', '9th', 'Grade', 'Center', '-', '13501', 'Hollypark', 'Houston', ',', 'TX', '77015', 'Harvey']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7188d60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT : OPEN SHELTER : North Shore 9th Grade Center - 13501 Hollypark Houston , TX 77015 Harvey'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd1c378b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"location_name\": \"North Shore\", \"start_idx\": 21, \"end_idx\": 31}, {\"location_name\": \"Houston\", \"start_idx\": 68, \"end_idx\": 74}, {\"location_name\": \"TX\", \"start_idx\": 78, \"end_idx\": 79}]'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoparse.topo_recog(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56bc0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "jsoned = json.loads(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5af05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a60a656c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @ReadyHarris: OPEN SHELTER: North Shore 9th Grade Center -  13501 Hollypark Houston, TX 77015 #Harvey @DisasterPIO'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84f521b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @ReadyHarris: OPEN SHELTER: North Shore 9th Grade Center -  13501 Hollypark Houston, TX 77015 #Harvey @DisasterPIO'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c93c9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tudio from Buffalo Bayou. About to move broadcast to second floor. #Harvey #KHOU11 https://t.coâ€¦'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].iloc[1][44:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "007b1e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% until completion\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "following_topo_recogs = []\n",
    "wait_counter= 0\n",
    "total_length = len(df['text'])\n",
    "for content in df['text']:\n",
    "    following_topo_recogs.append(geoparse.topo_recog(content))\n",
    "    clear_output(wait = True)\n",
    "    wait_counter += 1 \n",
    "    print(\"{}% until completion\".format((wait_counter / total_length) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "462e2394",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-f37c185966a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mresults_tpr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfollowing_topo_recogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mnew_dict_to_save\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_tpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'location_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "new_dict_to_save = {}\n",
    "for idn in df['id']:\n",
    "    for results_tpr in following_topo_recogs:\n",
    "        new_dict_to_save[idn] = results_tpr['location_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8338af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Neuro TPR-res'] = following_topo_recogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ecab7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_tosql = df.drop(columns = ['index'])#.to_sql('NueroTPR-dataset', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3c504e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_tosql['created_at'] = pd.to_datetime(new_df_tosql['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a3e44dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_tosql.rename(columns = {'Neuro TPR-res':'neuro_data'},inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "072c74e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_tosql['neuro_data'] = new_df_tosql['neuro_data'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "3d914f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('NeuroTPR-dataset',conn, \n",
    "                      if_exists = 'replace', \n",
    "                      index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "b0f4dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correction_of_neuro'] = df['correction_of_neuro'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "1b4fb42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USA'"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#integer IDS round up... I need to fix that \n",
    "\"RT @miguefuente: #HuracÃ¡n #Harvey â›ˆðŸŒŠðŸŒªðŸ’¨ Para los que estais en USA,si no controlais el inglÃ©s,es muy buena idea seguir a @FEMAespanol @Spaiâ€¦\"[62:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf05197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency issues\n",
    "'''\n",
    "h5py package (in my case to 2.10.0) <= needs to be done'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "56cf2a90",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 3 (char 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-630-2fdd2e844ff4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'correction_of_neuro'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\NeuroTPR\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NeuroTPR\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NeuroTPR\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 3 (char 2)"
     ]
    }
   ],
   "source": [
    "json.loads(df['correction_of_neuro'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "903a2eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'location_name': 'Buffalo Bayou', 'start_idx': 55, 'end_idx': 68}]\""
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['correction_of_neuro'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0bcc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuroTPR-env",
   "language": "python",
   "name": "neurotpr-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
